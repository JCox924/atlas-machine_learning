{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Lets import our libs",
   "id": "eaf0b9e24d6e1d87"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T08:55:33.958239Z",
     "start_time": "2024-11-26T08:55:33.947240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow.keras as K"
   ],
   "id": "17575baa0b6935db",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Loading the model",
   "id": "43ef13c34baa9419"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T08:55:35.311820Z",
     "start_time": "2024-11-26T08:55:33.964238Z"
    }
   },
   "cell_type": "code",
   "source": "model = K.models.load_model('yolo.h5')",
   "id": "c16d514a1146d5d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Define our class names",
   "id": "a3a2afbcb9caab35"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T08:55:35.357783Z",
     "start_time": "2024-11-26T08:55:35.343780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class_names = []\n",
    "with open('coco_classes.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        class_names.append(line.rstrip())\n",
    "print(class_names)"
   ],
   "id": "464817c2f5633c62",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T10:15:36.332004Z",
     "start_time": "2024-11-26T08:55:35.404781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Yolo:\n",
    "    \"\"\"\n",
    "    Yolo class contains methods:\n",
    "        __init__(self, model_path, classes_path, class_t, nms_t, anchors)\n",
    "        process_outputs(self, outputs, image_size)\n",
    "        filter_boxes(self, boxes, box_confidences, box_class_probs)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_path, classes_path, class_t, nms_t, anchors):\n",
    "        \"\"\"\n",
    "        Initialize Yolo class instance\n",
    "\n",
    "        Args:\n",
    "            model_path {string} -- path to where a\n",
    "                Darknet Keras model is stored\n",
    "\n",
    "            classes_path {string} -- path to where the list of class\n",
    "                names used for the Darknet model,\n",
    "                    listed in order of index, can be found\n",
    "\n",
    "            class_t {float} -- representing the box score threshold\n",
    "                for the initial filtering step\n",
    "\n",
    "            nms_t {float} -- shape (outputs, anchor_boxes, 2)\n",
    "                containing all the anchor boxes\n",
    "\n",
    "            anchors {numpy.ndarray} -- shape (outputs, anchor_boxes, 2)\n",
    "        \"\"\"\n",
    "        self.model = K.models.load_model(model_path)\n",
    "        self.class_names = []\n",
    "        with open(classes_path, 'r') as f:\n",
    "            for line in f:\n",
    "                self.class_names.append(line.rstrip())\n",
    "            self.class_t = class_t\n",
    "            self.nms_t = nms_t\n",
    "            self.anchors = anchors\n",
    "\n",
    "    @staticmethod\n",
    "    def load_images(folder_path):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            folder_path: {string} representing the path to the folder holding all the images to load\n",
    "        Returns:\n",
    "            a tuple of (images, image_paths)\n",
    "        \"\"\"\n",
    "        images = []\n",
    "        image_paths = []\n",
    "        \n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            if os.path.isfile(file_path):\n",
    "                image = cv2.imread(file_path)\n",
    "                if image is not None:\n",
    "                    images.append(image)\n",
    "                    image_paths.append(file_path)\n",
    "    \n",
    "        return images, image_paths\n",
    "\n",
    "    def process_outputs(self, outputs, image_size):\n",
    "        \"\"\"\n",
    "        Process the outputs for a single image\n",
    "\n",
    "        Args:\n",
    "            outputs: list of ndarrays of the predictions from the\n",
    "                Darknet model for a single image\n",
    "            image_size: numpy.ndarray containing the image's original size\n",
    "                [image_height, image_width]\n",
    "\n",
    "        Returns:\n",
    "            tuple of (boxes, box_confidences, box_class_probs)\n",
    "        \"\"\"\n",
    "        boxes = []\n",
    "        box_confidences = []\n",
    "        box_class_probs = []\n",
    "\n",
    "        input_shape = self.model.input.shape\n",
    "        input_height = input_shape[1]\n",
    "        input_width = input_shape[2]\n",
    "        image_height, image_width = image_size\n",
    "\n",
    "        for output, anchors in zip(outputs, self.anchors):\n",
    "            grid_height, grid_width, anchor_boxes = output.shape[:3]\n",
    "\n",
    "            tx = output[..., 0]\n",
    "            ty = output[..., 1]\n",
    "            tw = output[..., 2]\n",
    "            th = output[..., 3]\n",
    "\n",
    "            tx = 1 / (1 + np.exp(-tx))\n",
    "            ty = 1 / (1 + np.exp(-ty))\n",
    "\n",
    "            c_x = np.arange(grid_width)\n",
    "            c_y = np.arange(grid_height)\n",
    "            c_x, c_y = np.meshgrid(c_x, c_y)\n",
    "\n",
    "            c_x = c_x[..., np.newaxis]\n",
    "            c_y = c_y[..., np.newaxis]\n",
    "\n",
    "            bx = (tx + c_x) / grid_width\n",
    "            by = (ty + c_y) / grid_height\n",
    "\n",
    "            anchors = anchors.reshape((1, 1, anchor_boxes, 2))\n",
    "            pw = anchors[..., 0]\n",
    "            ph = anchors[..., 1]\n",
    "\n",
    "            tw = np.exp(tw) * pw / input_width\n",
    "            th = np.exp(th) * ph / input_height\n",
    "\n",
    "            x1 = (bx - tw / 2) * image_width\n",
    "            y1 = (by - th / 2) * image_height\n",
    "            x2 = (bx + tw / 2) * image_width\n",
    "            y2 = (by + th / 2) * image_height\n",
    "\n",
    "            boxes_per_output = np.stack((x1, y1, x2, y2), axis=-1)\n",
    "            boxes.append(boxes_per_output)\n",
    "\n",
    "            box_confidence = 1 / (1 + np.exp(-output[..., 4]))\n",
    "            box_confidence = box_confidence[..., np.newaxis]\n",
    "            box_confidences.append(box_confidence)\n",
    "\n",
    "            class_probs = 1 / (1 + np.exp(-output[..., 5:]))\n",
    "            box_class_probs.append(class_probs)\n",
    "\n",
    "        return boxes, box_confidences, box_class_probs\n",
    "\n",
    "    def filter_boxes(self, boxes, box_confidences, box_class_probs):\n",
    "        \"\"\"\n",
    "        Filters out boxes based on objectness score and class probabilities.\n",
    "\n",
    "        Parameters:\n",
    "        - boxes: list of numpy.ndarrays of shape\n",
    "          (grid_height, grid_width, anchor_boxes, 4)\n",
    "        - box_confidences: list of numpy.ndarrays of shape\n",
    "          (grid_height, grid_width, anchor_boxes, 1)\n",
    "        - box_class_probs: list of numpy.ndarrays of shape\n",
    "          (grid_height, grid_width, anchor_boxes, classes)\n",
    "\n",
    "        Returns:\n",
    "        - tuple of (filtered_boxes, box_classes, box_scores):\n",
    "          - filtered_boxes: numpy.ndarray of shape (?, 4)\n",
    "          - box_classes: numpy.ndarray of shape (?,)\n",
    "          - box_scores: numpy.ndarray of shape (?)\n",
    "        \"\"\"\n",
    "        filtered_boxes = []\n",
    "        box_classes = []\n",
    "        box_scores = []\n",
    "\n",
    "        for b, c, p in zip(boxes, box_confidences, box_class_probs):\n",
    "            scores = c * p\n",
    "            classes = np.argmax(scores, axis=-1)\n",
    "            class_scores = np.max(scores, axis=-1)\n",
    "\n",
    "            mask = class_scores >= self.class_t\n",
    "\n",
    "            filtered_boxes.append(b[mask])\n",
    "            box_classes.append(classes[mask])\n",
    "            box_scores.append(class_scores[mask])\n",
    "\n",
    "        if len(filtered_boxes) == 0:\n",
    "            return (np.array([]), np.array([]), np.array([]))\n",
    "\n",
    "        filtered_boxes = np.concatenate(filtered_boxes, axis=0)\n",
    "        box_classes = np.concatenate(box_classes, axis=0)\n",
    "        box_scores = np.concatenate(box_scores, axis=0)\n",
    "\n",
    "        return filtered_boxes, box_classes, box_scores\n",
    "\n",
    "    def non_max_suppression(self, filtered_boxes, box_classes, box_scores):\n",
    "        \"\"\"\n",
    "        Applies Non-max suppression to filtered bounding boxes.\n",
    "\n",
    "        Args:\n",
    "            filtered_boxes: numpy.ndarray of shape (?, 4) containing the filtered bounding boxes\n",
    "            box_classes: numpy.ndarray of shape (?,) containing the class number for the class\n",
    "            box_scores: numpy.ndarray of shape (?) containing the box scores for each box\n",
    "\n",
    "        Returns:\n",
    "            tuple of (box_predictions, predicted_box_classes, predicted_box_scores):\n",
    "                box_predictions: numpy.ndarray of shape (?, 4)\n",
    "                predicted_box_classes: numpy.ndarray of shape (?,)\n",
    "                predicted_box_scores: numpy.ndarray of shape (?)\n",
    "        \"\"\"\n",
    "        box_predictions = []\n",
    "        predicted_box_classes = []\n",
    "        predicted_box_scores = []\n",
    "\n",
    "        unique_classes = np.unique(box_classes)\n",
    "\n",
    "        for cls in unique_classes:\n",
    "            idxs = np.where(box_classes == cls)\n",
    "\n",
    "            cls_boxes = filtered_boxes[idxs]\n",
    "            cls_box_scores = box_scores[idxs]\n",
    "            cls_box_classes = box_classes[idxs]\n",
    "\n",
    "            sorted_idx = np.argsort(-cls_box_scores)\n",
    "            cls_boxes = cls_boxes[sorted_idx]\n",
    "            cls_box_scores = cls_box_scores[sorted_idx]\n",
    "\n",
    "            while len(cls_boxes) > 0:\n",
    "                box_predictions.append(cls_boxes[0])\n",
    "                predicted_box_classes.append(cls)\n",
    "                predicted_box_scores.append(cls_box_scores[0])\n",
    "\n",
    "                if len(cls_boxes) == 1:\n",
    "                    break\n",
    "\n",
    "                x1 = np.maximum(cls_boxes[0, 0], cls_boxes[1:, 0])\n",
    "                y1 = np.maximum(cls_boxes[0, 1], cls_boxes[1:, 1])\n",
    "                x2 = np.minimum(cls_boxes[0, 2], cls_boxes[1:, 2])\n",
    "                y2 = np.minimum(cls_boxes[0, 3], cls_boxes[1:, 3])\n",
    "\n",
    "                inter_area = np.maximum(0, x2 - x1) * np.maximum(0, y2 - y1)\n",
    "\n",
    "                box_area = (cls_boxes[0, 2] - cls_boxes[0, 0]) * (cls_boxes[0, 3] - cls_boxes[0, 1])\n",
    "                cls_boxes_areas = (cls_boxes[1:, 2] - cls_boxes[1:, 0]) * (cls_boxes[1:, 3] - cls_boxes[1:, 1])\n",
    "\n",
    "                iou = inter_area / (box_area + cls_boxes_areas - inter_area)\n",
    "\n",
    "                keep_idxs = np.where(iou < self.nms_t)[0]\n",
    "                cls_boxes = cls_boxes[keep_idxs + 1]\n",
    "                cls_box_scores = cls_box_scores[keep_idxs + 1]\n",
    "\n",
    "        box_predictions = np.array(box_predictions)\n",
    "        predicted_box_classes = np.array(predicted_box_classes)\n",
    "        predicted_box_scores = np.array(predicted_box_scores)\n",
    "\n",
    "        return box_predictions, predicted_box_classes, predicted_box_scores\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    np.random.seed(2)\n",
    "    anchors = np.array([[[116, 90], [156, 198], [373, 326]],\n",
    "                        [[30, 61], [62, 45], [59, 119]],\n",
    "                        [[10, 13], [16, 30], [33, 23]]])\n",
    "    yolo = Yolo('yolo.h5', 'coco_classes.txt', 0.6, 0.5, anchors)\n",
    "    images, image_paths = yolo.load_images('imgs/yolo_images/yolo/')\n",
    "    image_paths, images = zip(*sorted(zip(image_paths, images)))\n",
    "    i = np.random.randint(0, len(images))\n",
    "    print(i)\n",
    "    print(image_paths[i])\n",
    "    cv2.imshow(image_paths[i], images[i])\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ],
   "id": "c5e1feb1acf04672",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "0\n",
      "imgs/yolo_images/yolo/dog.jpg\n"
     ]
    }
   ],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
